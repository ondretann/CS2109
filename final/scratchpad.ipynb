{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d017333",
   "metadata": {},
   "source": [
    "# Final Assessment Scratch Pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d00386",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea516aa7",
   "metadata": {},
   "source": [
    "1. Please use only this Jupyter notebook to work on your model, and **do not use any extra files**. If you need to define helper classes or functions, feel free to do so in this notebook.\n",
    "2. This template is intended to be general, but it may not cover every use case. The sections are given so that it will be easier for us to grade your submission. If your specific use case isn't addressed, **you may add new Markdown or code blocks to this notebook**. However, please **don't delete any existing blocks**.\n",
    "3. If you don't think a particular section of this template is necessary for your work, **you may skip it**. Be sure to explain clearly why you decided to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14a2d8",
   "metadata": {},
   "source": [
    "##### Overview\n",
    "I have created my model by emplying the basic preprocessing techniques and running a very simple model, after which I continuously augment and preprocess my data further while fine tuning my model to give the best results.\n",
    "\n",
    "##### 1. Descriptive Analysis\n",
    "I printed the max and min of the image dataset to view the range of values. Additionally, I printed the number of labels for preprocessing later on.\n",
    "\n",
    "##### 2. Detection and Handling of Missing Values\n",
    "I printed the number of missing values in X and y. Samples with missing y value (label) will be redundant in a supervised learning neural network model, hence they were removed from the dataset.\n",
    "Since the number of missing values in X is too high, we cannot remove samples containing them. Fortunately, there is no sample where then number of missing values is too high (>30), hence I have decided to fill them wih the mean of that respective channel and image. \n",
    "\n",
    "##### 3. Detection and Handling of Outliers\n",
    "The data were provided as image samples containing channels of pixels. Thus, integer values should range from 0 to 255. I have decided to clip them to minimum 0 and maximum 255 given the context of the problem.\n",
    "\n",
    "##### 4. Detection and Handling of Class Imbalance \n",
    "Class imbalance was evident in this dataset where class 0 dominated the other 2. There were several ways I approached this issue. \n",
    "Firstly, I chose oversampling over undersampling as the minority classes had too few samples, especially for deep learning neural networks which required a huge dataset to be effective. I did the naive approach of oversampling classes 1 and 2 to match the number of samples of class 0 by duplicating the samples of minority classes. While SMOTE techniques may have been more effective at replicating data of minority classes, I do not have access to imbalanced-learning library. \n",
    "After creating the model, I realised that image augmentation techniques like rotating and flipping are applicable here. The minority classes can be filled with augmented samples of the current minority classes and will allow my model to generalise better to these classes. This is evident in the increase in f1 score of my model.\n",
    "\n",
    "##### 5. Understanding Relationship Between Variables\n",
    "To understand the relationship, I created a correlation matrix of the images. However, it was not very useful since each data represents pixels.\n",
    "\n",
    "##### 6. Data Visualization\n",
    "I tried to display image of each sample but it was not useful.\n",
    "\n",
    "##### 7. General Preprocessing\n",
    "Other preprocessing techniques I employed was normalization, where pixel values were divided by 255. This improves convergence speed of the model since it is a gradient-based optimisation model.\n",
    " \n",
    "##### 8. Feature Selection \n",
    "Feature selection techniques like PCA may not be very useful here as neural networks are already able to effectively handle large number of features and automatically determine the hierachical ordering of the features. Employing these techniques may only result in overhead costs with no added efficiency or even worse, loss of information.\n",
    "\n",
    "##### 9. Feature Engineering\n",
    "Data augmentation explained in point 4 to create more samples can be considered as feature engineering for more accurate results.\n",
    "\n",
    "##### 10. Creating Models\n",
    "I employed a simple CNN model whereby a mixture of Conv2d, Maxpool2d, ReLU and Linear layers were used in the architecture. Convolutional layers were used to slide across the image to recognise if there is any apparent pattern or feature that is detectable, after which ReLU activation layers were used for non-linearity. Maxpooling was also utilised as it could help by downsampling and reducing the dimensions, lightening the load on the network. The data then passes through the 2 fully connected layers of neurons and the final output size is 3 to match the number of classes.\n",
    "As I have limited knowledge on the architecture capabilities and advanced models will use up too much computational resources, I only tested this CNN model and another CNN model with dropout.\n",
    "For model training, optimiser adam and cross entropy loss was used, similar to that of earlier problem sets.\n",
    "\n",
    "##### 11. Model Evaluation\n",
    "I only employed 2 models for evaluations, which are my original CNN model and CNN with dropout model. While both were effective in achieving a high f1 score, my original CNN model consistently outperformed CNN with dropout model, hence I have decided to stick to the former.\n",
    "\n",
    "##### 12. Hyperparameters Search\n",
    "Hyperparameters that were considered for testing are learning rates, number and size of hidden layers and activation function. I employed grid search for hyperparameter search and best results were 2 layers, 0.01 learning rate and ReLU activation function.\n",
    "Additionally, learning rates were changed marginally and the loss after each epoch was printed out for me to visually inspect the effectiveness of change. This also allows me to determine the best value for number of epochs that will allow the model to converge without using too much resources\n",
    "\n",
    "##### Conclusion\n",
    "In conclusion, tackling this problem set required knowledge from all of the previous problem sets combined. Oversampling and data augmentation were skills imbued into me in ps7 and I was able to judge which techniques were more effective. Additionally, employing CNN for deep learning was challenging given the myraid of factors and choices I had to consider. There isn't a one-size-fit-all solution to this problem and this final model is one I have created with thorough experimentation, testing and consideration for the context of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022cb4cd",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcaf29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27103374",
   "metadata": {},
   "source": [
    "# Workings (Not Graded)\n",
    "\n",
    "You will do your working below. Note that anything below this section will not be graded, but we might counter-check what you wrote in the report above with your workings to make sure that you actually did what you claimed to have done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c6cd4",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Here, we import some packages necessary to run this notebook. In addition, you may import other packages as well. Do note that when submitting your model, you may only use packages that are available in Coursemology (see `main.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "cded1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c35d7",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "The dataset `data/images.npy` is of size $(N, C, H, W)$, where $N$, $C$, $H$, and $W$ correspond to the number of data, image channels, image width, and image height, respectively.\n",
    "\n",
    "A code snippet that loads the data is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09da291",
   "metadata": {},
   "source": [
    "### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "6297e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2911, 3, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    images = data['image']\n",
    "    labels = data['label']\n",
    "    \n",
    "print('Shape:', images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe832b6",
   "metadata": {},
   "source": [
    "## Data Exploration & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a464c",
   "metadata": {},
   "source": [
    "### 1. Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "3b1f62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 2392, 1.0: 203, 2.0: 25, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1, nan: 1})\n",
      "10000.0\n",
      "-10000.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.25, random_state=42)\n",
    "print(collections.Counter(labels))\n",
    "print(np.nanmax(images))\n",
    "print(np.nanmin(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb61967",
   "metadata": {},
   "source": [
    "### 2. Detection and Handling of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "4bb9cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16591\n",
      "223\n",
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ondre/Library/Python/3.9/lib/python/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train).sum()) #too many to remove samples\n",
    "print(np.isnan(y_train).sum())\n",
    "print(np.where(np.sum(np.isnan(X_train), axis=(1,2,3)) > 30)) #0\n",
    "\n",
    "nanarr = np.isnan(y_train)\n",
    "y_train = np.delete(y_train, nanarr)\n",
    "X_train = np.delete(X_train, nanarr, axis=0)\n",
    "\n",
    "nanarr = np.isnan(y_test)\n",
    "y_test = np.delete(y_test, nanarr)\n",
    "X_test = np.delete(X_test, nanarr, axis=0)\n",
    "\n",
    "for image in X_train:\n",
    "    for channel in image:\n",
    "        np.nan_to_num(image, copy=False, nan=np.nanmean(channel))\n",
    "\n",
    "for image in X_test:\n",
    "    for channel in image:\n",
    "        np.nan_to_num(image, copy=False, nan=np.nanmean(channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adcb9cd",
   "metadata": {},
   "source": [
    "### 3. Detection and Handling of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "ed1c17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.clip(X_train, 0, 255)\n",
    "X_test = np.clip(X_test, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4916043",
   "metadata": {},
   "source": [
    "### 4. Detection and Handling of Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "ad3ab20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = np.count_nonzero(y_train == 0)\n",
    "n1 = np.count_nonzero(y_train == 1)\n",
    "n2 = np.count_nonzero(y_train == 2)\n",
    "\n",
    "i1 = np.ndarray.flatten(np.array(np.where(y_train == 1)))\n",
    "i2 = np.ndarray.flatten(np.array(np.where(y_train == 2)))\n",
    "\n",
    "indices1 = np.random.choice(i1, n0 - n1, replace=True)\n",
    "indices2 = np.random.choice(i2, n0 - n2, replace=True)\n",
    "\n",
    "# X_train = np.concatenate([X_train, X_train[indices1], X_train[indices2]], axis=0)\n",
    "y_train = np.concatenate([y_train, y_train[indices1], y_train[indices2]], axis=0)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(), \n",
    "])\n",
    "\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "augmented_imgs = []\n",
    "\n",
    "for i in indices1:\n",
    "    augmented_imgs.append(transform(X_tensor[i]))\n",
    "\n",
    "for i in indices2:\n",
    "    augmented_imgs.append(transform(X_tensor[i]))\n",
    "\n",
    "augmented_data = torch.stack(augmented_imgs)\n",
    "\n",
    "X_tensor = torch.cat([X_tensor, augmented_data])\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552a795",
   "metadata": {},
   "source": [
    "### 5. Understanding Relationship Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "29ddbbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>-0.013120</td>\n",
       "      <td>-0.126637</td>\n",
       "      <td>-0.010793</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>0.018146</td>\n",
       "      <td>0.026122</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027124</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.041292</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>-0.008026</td>\n",
       "      <td>-0.034427</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>-0.067451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.811828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425961</td>\n",
       "      <td>0.187306</td>\n",
       "      <td>-0.058447</td>\n",
       "      <td>-0.050554</td>\n",
       "      <td>-0.004171</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>0.033038</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>-0.017026</td>\n",
       "      <td>-0.007230</td>\n",
       "      <td>-0.044260</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>-0.073475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013120</td>\n",
       "      <td>0.425961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666662</td>\n",
       "      <td>-0.022414</td>\n",
       "      <td>-0.064303</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>-0.002567</td>\n",
       "      <td>-0.001350</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030620</td>\n",
       "      <td>-0.023429</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>0.033929</td>\n",
       "      <td>-0.034616</td>\n",
       "      <td>-0.014785</td>\n",
       "      <td>-0.042216</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.015475</td>\n",
       "      <td>-0.012182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.126637</td>\n",
       "      <td>0.187306</td>\n",
       "      <td>0.666662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.573423</td>\n",
       "      <td>0.226178</td>\n",
       "      <td>-0.079671</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.002907</td>\n",
       "      <td>0.034606</td>\n",
       "      <td>-0.044391</td>\n",
       "      <td>-0.001801</td>\n",
       "      <td>-0.041651</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>-0.005623</td>\n",
       "      <td>0.005147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.010793</td>\n",
       "      <td>-0.058447</td>\n",
       "      <td>-0.022414</td>\n",
       "      <td>0.573423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505247</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>-0.013225</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>-0.004748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028643</td>\n",
       "      <td>-0.032153</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>-0.023203</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>-0.034578</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.011147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>-0.008026</td>\n",
       "      <td>-0.007230</td>\n",
       "      <td>-0.014785</td>\n",
       "      <td>-0.001801</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.014840</td>\n",
       "      <td>0.028430</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>-0.009905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012398</td>\n",
       "      <td>0.035155</td>\n",
       "      <td>-0.019344</td>\n",
       "      <td>-0.016566</td>\n",
       "      <td>-0.028510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>0.014471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.034427</td>\n",
       "      <td>-0.044260</td>\n",
       "      <td>-0.042216</td>\n",
       "      <td>-0.041651</td>\n",
       "      <td>-0.034578</td>\n",
       "      <td>-0.002900</td>\n",
       "      <td>0.016864</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.010860</td>\n",
       "      <td>-0.036161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013859</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>0.016422</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015670</td>\n",
       "      <td>-0.025269</td>\n",
       "      <td>-0.016287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.024370</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>-0.004804</td>\n",
       "      <td>-0.022666</td>\n",
       "      <td>-0.024483</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012251</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>-0.015670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.010838</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>-0.015475</td>\n",
       "      <td>-0.005623</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>-0.022815</td>\n",
       "      <td>-0.042358</td>\n",
       "      <td>-0.037637</td>\n",
       "      <td>-0.023273</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014601</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.054847</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.025269</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.067451</td>\n",
       "      <td>-0.073475</td>\n",
       "      <td>-0.012182</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020961</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>-0.029366</td>\n",
       "      <td>-0.006914</td>\n",
       "      <td>-0.018756</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>-0.016287</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.811828 -0.013120 -0.126637 -0.010793 -0.005413 -0.010508   \n",
       "1    0.811828  1.000000  0.425961  0.187306 -0.058447 -0.050554 -0.004171   \n",
       "2   -0.013120  0.425961  1.000000  0.666662 -0.022414 -0.064303  0.001941   \n",
       "3   -0.126637  0.187306  0.666662  1.000000  0.573423  0.226178 -0.079671   \n",
       "4   -0.010793 -0.058447 -0.022414  0.573423  1.000000  0.505247  0.001163   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763 -0.008026 -0.007230 -0.014785 -0.001801  0.005943 -0.009094 -0.014840   \n",
       "764 -0.034427 -0.044260 -0.042216 -0.041651 -0.034578 -0.002900  0.016864   \n",
       "765  0.024370  0.017762 -0.000154 -0.007122 -0.004804 -0.022666 -0.024483   \n",
       "766  0.010838  0.006482 -0.015475 -0.005623  0.010781 -0.022815 -0.042358   \n",
       "767 -0.067451 -0.073475 -0.012182  0.005147  0.011147  0.007335  0.001019   \n",
       "\n",
       "          7         8         9    ...       758       759       760  \\\n",
       "0    0.018146  0.026122  0.016918  ...  0.027124 -0.004464  0.031798   \n",
       "1    0.007502  0.008589  0.011927  ...  0.003654 -0.031993  0.033038   \n",
       "2   -0.002567 -0.001350  0.011261  ... -0.030620 -0.023429  0.019626   \n",
       "3   -0.039492  0.006822  0.016747  ...  0.010456 -0.002760 -0.002907   \n",
       "4   -0.013225  0.005651 -0.004748  ...  0.028643 -0.032153 -0.025641   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "763  0.028430  0.028841 -0.009905  ... -0.012398  0.035155 -0.019344   \n",
       "764  0.014948  0.010860 -0.036161  ... -0.013859  0.009284  0.003307   \n",
       "765  0.022693  0.020411 -0.001285  ... -0.012251  0.010685  0.028589   \n",
       "766 -0.037637 -0.023273 -0.002566  ... -0.014601 -0.013886 -0.019750   \n",
       "767  0.010929  0.020485  0.013382  ... -0.020961  0.058580 -0.029366   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0    0.041292  0.007249 -0.008026 -0.034427  0.024370  0.010838 -0.067451  \n",
       "1    0.049700 -0.017026 -0.007230 -0.044260  0.017762  0.006482 -0.073475  \n",
       "2    0.033929 -0.034616 -0.014785 -0.042216 -0.000154 -0.015475 -0.012182  \n",
       "3    0.034606 -0.044391 -0.001801 -0.041651 -0.007122 -0.005623  0.005147  \n",
       "4    0.014317 -0.023203  0.005943 -0.034578 -0.004804  0.010781  0.011147  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "763 -0.016566 -0.028510  1.000000  0.043738  0.024661 -0.010145  0.014471  \n",
       "764 -0.002169  0.016422  0.043738  1.000000 -0.015670 -0.025269 -0.016287  \n",
       "765 -0.000579 -0.010000  0.024661 -0.015670  1.000000  0.008342  0.029700  \n",
       "766  0.031450  0.054847 -0.010145 -0.025269  0.008342  1.000000  0.001482  \n",
       "767 -0.006914 -0.018756  0.014471 -0.016287  0.029700  0.001482  1.000000  \n",
       "\n",
       "[768 rows x 768 columns]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train.reshape(X_train.shape[0], 768)).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fb315",
   "metadata": {},
   "source": [
    "### 6. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "93f82e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x295a639d0>"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7eebcf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e3383",
   "metadata": {},
   "source": [
    "### 7. General Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "19174365",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = X_tensor/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3aa527",
   "metadata": {},
   "source": [
    "### 8. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85808bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4921e8ca",
   "metadata": {},
   "source": [
    "### 9. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcde626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa676c3f",
   "metadata": {},
   "source": [
    "## Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589b37e4",
   "metadata": {},
   "source": [
    "### 10. Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "d8dffd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "def train_model(loader, model):\n",
    "    \n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = 1e-2) \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()  \n",
    "\n",
    "    epoch_losses = []\n",
    "    for i in range(30):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for idx, data in enumerate(loader):\n",
    "            x, y = data\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            epoch_loss += loss\n",
    "\n",
    "        epoch_loss = epoch_loss / len(loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print (\"Epoch: {}, Loss: {}\".format(i, epoch_loss))\n",
    "        \n",
    "    return model\n",
    "\n",
    "# class DropoutCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DroutCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.flatten = nn.Flatten()\n",
    "\n",
    "#         # Apply dropout to the fully connected layers\n",
    "#         self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "\n",
    "#         self.fc2 = nn.Linear(128, 3) \n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "    #     x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "    #     x = self.flatten(x)\n",
    "\n",
    "    #     # Apply dropout before the first fully connected layer\n",
    "    #     x = self.dropout(self.relu3(self.fc1(x)))\n",
    "\n",
    "    #     x = self.fc2(x)\n",
    "    #     return x\n",
    "    \n",
    "class SimpleCNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SimpleCNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "            self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "            self.fc2 = nn.Linear(64, 3)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.conv1(x))\n",
    "            x = self.maxpool(x)\n",
    "            x = self.relu(self.conv2(x))\n",
    "            x = self.maxpool(x)\n",
    "            x = x.view(-1, 64 * 4 * 4)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bf3c0",
   "metadata": {},
   "source": [
    "### 11. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "9245ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.8969213366508484\n",
      "Epoch: 1, Loss: 0.21801592409610748\n",
      "Epoch: 2, Loss: 0.1376160830259323\n",
      "Epoch: 3, Loss: 0.10047291219234467\n",
      "Epoch: 4, Loss: 0.07239808887243271\n",
      "Epoch: 5, Loss: 0.07328108698129654\n",
      "Epoch: 6, Loss: 0.047382958233356476\n",
      "Epoch: 7, Loss: 0.03596659004688263\n",
      "Epoch: 8, Loss: 0.02296442724764347\n",
      "Epoch: 9, Loss: 0.024021951481699944\n",
      "Epoch: 10, Loss: 0.022847536951303482\n",
      "Epoch: 11, Loss: 0.00797217059880495\n",
      "Epoch: 12, Loss: 0.013324185274541378\n",
      "Epoch: 13, Loss: 0.03835529834032059\n",
      "Epoch: 14, Loss: 0.025032324716448784\n",
      "Epoch: 15, Loss: 0.026665616780519485\n",
      "Epoch: 16, Loss: 0.022218773141503334\n",
      "Epoch: 17, Loss: 0.008415067568421364\n",
      "Epoch: 18, Loss: 0.010961787775158882\n",
      "Epoch: 19, Loss: 0.009696359746158123\n",
      "Epoch: 20, Loss: 0.0048818280920386314\n",
      "Epoch: 21, Loss: 0.0021836250089108944\n",
      "Epoch: 22, Loss: 0.005443689879029989\n",
      "Epoch: 23, Loss: 0.015661148354411125\n",
      "Epoch: 24, Loss: 0.0461697056889534\n",
      "Epoch: 25, Loss: 0.053487628698349\n",
      "Epoch: 26, Loss: 0.010371238924562931\n",
      "Epoch: 27, Loss: 0.0019433198031038046\n",
      "Epoch: 28, Loss: 0.0006200239877216518\n",
      "Epoch: 29, Loss: 0.00013909144036006182\n",
      "F1 Score (macro): 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "model = train_model(loader, SimpleCNN())\n",
    "y_pred = model.forward(test_tensor)\n",
    "y_pred = torch.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"F1 Score (macro): {0:.2f}\".format(f1_score(y_test, y_pred, average='macro'))) # You may encounter errors, you are expected to figure out what's the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa31404",
   "metadata": {},
   "source": [
    "### 12. Hyperparameters Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "81addd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50)}"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [(50,), (100,), (50,50), (100,50)],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_tensor.reshape(X_tensor.shape[0], 768), y_tensor)\n",
    "\n",
    "grid_search.best_params_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
